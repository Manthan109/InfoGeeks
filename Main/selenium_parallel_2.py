# -*- coding: utf-8 -*-
'''
Selenium_parallel_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YnNz_E-hYcuNa9FbqQC0cqurzhdf6B8t


Run the following command on the main .ipynb file to install selenium

!pip install selenium
!apt-get update # to update ubuntu to correctly run apt install
!apt install chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver /usr/bin


# creating a chrome instance. 
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options) # repalce the first argument with the path of your driver

'''

# imports
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup
import time

# function for getting links from the specified category
def link_from_category(category_link, category, n_pages):
  class_from_categ = {"News":"dbsr", "Videos":"yuRUbf"} #class tag for categories
  class_tag = ""
  class_tag = class_from_categ[category]

  results = [] # list for storing all the links


  for page in range(1, n_pages):
    url = category_link +  str((page - 1) * 10) 
    driver.get(url)

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    search = soup.find_all('div', class_=class_tag )
    for h in search:
        results.append(h.a.get('href'))

    
  return results

def links_for_search(query, newslinks_results, n_pages=10):

  # redirecting to google.com
  
  driver.get("https://www.google.com")

  # accessing the search bar and searching the specified query
  search_bar = driver.find_element_by_name("q")
  search_bar.clear()
  search_bar.send_keys(query)
  search_bar.send_keys(Keys.RETURN)

  # fetching the news and videos links for the specified query
  category_list = ["News"]
  category_link = []
  for i in category_list:
    category_link.append(driver.find_element_by_link_text(i).get_attribute('href'))


  # fetching all the links for news articles
  newslinks_results.append(link_from_category(category_link[0], "News",n_pages))